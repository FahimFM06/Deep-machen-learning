# ğŸ§  AI vs Human Text Detection  
### BiLSTM + Explainable AI (LIME) + Streamlit Deployment

---

## ğŸ”— Live Demo (Streamlit App)

ğŸ‘‰ https://kgtalyuz6zshlndvzgzzqz.streamlit.app/

---

## ğŸ“Œ Project Overview

This project builds an **AI vs Human text detection system** using deep learning and explainable AI.  
The goal is to classify whether a given text is:

- **Human-written (0)**
- **AI-generated (1)**

The final deployed system uses:

- âœ… **BiLSTM (Deep Learning Model)**
- âœ… **Word2Vec-based Tokenizer**
- âœ… **LIME (Explainable AI)**
- âœ… **Streamlit Web Application**

---

## ğŸ“Š Dataset

- Original dataset: ~487K samples
- Balanced dataset created: **150,000 samples**
  - 75,000 Human
  - 75,000 AI
- Split into:
  - 70% Train
  - 15% Validation
  - 15% Test

---

## ğŸ§¹ Data Preprocessing

The following preprocessing steps were applied:

- Lowercasing text
- Removing URLs
- Removing HTML tags
- Removing punctuation
- Removing numbers
- Removing extra spaces
- Removing very short texts
- Reset indexing
- Balanced sampling

---

## ğŸ§  Feature Representation Strategies Tested

Multiple vectorization techniques were explored:

### ğŸ”¹ Classical Approaches
- TF-IDF (Word-level)
- TF-IDF (Character-level)

### ğŸ”¹ Deep Learning Approaches
- Word2Vec embeddings (trained on dataset)
- Keras Tokenizer (sequence encoding)
- Transformer Tokenization:
  - DistilBERT
  - BERT
  - RoBERTa

---

## ğŸ¤– Models Tested

### âœ… Baseline Models
- Logistic Regression
- Naive Bayes
- Support Vector Machine (LinearSVC)

### âœ… Deep Learning Models
- LSTM
- BiLSTM
- CNN (1D Convolution)

### âœ… Transformer Models
- DistilBERT
- BERT
- RoBERTa

---

## ğŸ† Final Selected Model

After comparison, the **BiLSTM model** was selected because:

- Achieved ~**99.5% test accuracy**
- Strong generalization
- Stable validation performance
- Efficient inference time
- Easier integration with LIME for explainability

---

## ğŸ§© Final Architecture

**Pipeline:**

1. Input text  
2. Tokenizer (Word2Vec-based)  
3. Sequence padding (length = 300)  
4. BiLSTM model  
5. Output probability (AI vs Human)  
6. LIME explanation for word importance  

---

## ğŸ” Explainable AI (LIME)

LIME is used to:

- Highlight important words influencing prediction
- Show positive/negative contributions
- Provide local interpretability
- Improve transparency and trust

Output includes:
- Word importance list
- Visual explanation

---

## ğŸŒ Streamlit Web Application

The project includes a fully deployed Streamlit app with:

### Page 1 â€“ Project Summary
- Overview
- Workflow explanation
- Model details
- Architecture summary

### Page 2 â€“ Detection Platform
- Text input
- Prediction result
- Confidence score
- LIME explanation
- Word importance visualization

---

## ğŸ“ Project Structure

AI_vs_Human_Text_Detection/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ advanced_bilstm_model.keras
â”œâ”€â”€ tokenizer_word2vec.pkl
â”œâ”€â”€ README.md


---

## ğŸ“ˆ Performance

| Model | Accuracy |
|-------|----------|
| Logistic Regression | ~97% |
| SVM | ~98% |
| CNN | ~99% |
| **BiLSTM (Final)** | **~99.5%** |

---

## ğŸ¯ Key Contributions

âœ” Balanced dataset engineering  
âœ” Multi-vectorization comparison  
âœ” Classical + Deep + Transformer benchmarking  
âœ” BiLSTM optimization  
âœ” Explainable AI integration  
âœ” Full-stack ML deployment  

---

## ğŸ Final Outcome

This project delivers:

- A production-ready deep learning classifier  
- Explainable AI integration  
- Web deployment  
- Research-grade documentation  
- Portfolio-ready AI system  


